import ollama
import streamlit as st

from step_2_1 import chat_message_user, init_session_state


def chat_message_llm_stream(role: str, model: str, messages: list) -> dict:
    with st.chat_message(role):  # LLM ë©”ì‹œì§€ ì¶œë ¥
        with st.spinner("ëŒ€í™”ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            # ollama.chat() í•¨ìˆ˜ì˜ stream ë§¤ê°œë³€ìˆ˜ì— Trueë¥¼ ì „ë‹¬
            stream = ollama.chat(model=model, messages=messages, stream=True)

            # ìŠ¤íŠ¸ë¦¼ í˜•ì‹ì˜ ë°˜í™˜ê°’ì—ì„œ ë©”ì‹œì§€ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜(ì œë„¤ë ˆì´í„°)
            def stream_parser(stream):
                for chunk in stream:
                    yield chunk["message"]["content"]

            # st.write_stream() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íŠ¸ë¦¼ í˜•ì‹ì˜ ë©”ì‹œì§€ ì½˜í…ì¸ ë¥¼ ì¶œë ¥
            content = st.write_stream(stream_parser(stream))
            return dict(role="assistant", content=content)


if __name__ == "__main__":
    st.set_page_config(layout="wide")
    st.title("ğŸ¤– ë§Œë“¤ë©´ì„œ ë°°ìš°ëŠ” ì±—ë´‡")

    init_session_state(dict(msgs=[], running=False))  # ì„¸ì…˜ ì €ì¥ì†Œ ì´ˆê¸°í™”
    msgs: list = st.session_state["msgs"]
    running: bool = st.session_state["running"]

    # ì‚¬ìš©ìê°€ ëŒ€í™”ë¥¼ ì…ë ¥í•˜ë©´ 'running' ì„¸ì…˜ê°’ì„ Trueë¡œ ì§€ì •
    if "prompt" in st.session_state and st.session_state["prompt"] is not None:
        running = True
    else:
        running = False

    for row in msgs:  # msgsì— ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ í•˜ë‚˜ì”© ë°˜ë³µ ì²˜ë¦¬
        with st.chat_message(row["role"]):
            st.markdown(row["content"])

    # st.chat_input() í•¨ìˆ˜ í˜¸ì¶œ ì‹œ,
    #   1. disabled ë§¤ê°œë³€ìˆ˜ì— 'running' ì„¸ì…˜ê°’ì„ ì „ë‹¬í•˜ì—¬ ìœ„ì ¯ í™œì„±í™” ì—¬ë¶€ë¥¼ ê²°ì •
    #   2. key ë§¤ê°œë³€ìˆ˜ì— 'prompt'ë¥¼ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©ìì˜ ëŒ€í™” ì…ë ¥ ì—¬ë¶€ë¥¼ ì²´í¬í•˜ëŠ” ë° í™œìš©
    if prompt := st.chat_input("ëŒ€í™”ë¥¼ ì…ë ¥í•˜ì„¸ìš”!", disabled=running, key="prompt"):
        msg_user = chat_message_user(prompt)
        msgs.append(msg_user)  # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€

        msg_llm = chat_message_llm_stream("assistant", "gemma2:9b", msgs)
        msgs.append(msg_llm)  # LLM ë©”ì‹œì§€ ì¶”ê°€

        st.rerun()  # ì•±ì„ ì¬ì‹¤í–‰í•˜ì—¬ 'running' ì„¸ì…˜ê°’ì„ ì¬ì„¤ì •
